---
permalink: /
title: "Sizhe Chen's homepage"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

  
Biography
------
Hi! I am a Computer Science Ph.D. student at [UC Berkeley](https://eecs.berkeley.edu), fortunately advised by Prof. [David Wagner](https://people.eecs.berkeley.edu/~daw) in [Berkeley AI Research (BAIR)](https://bair.berkeley.edu). I am working as a visiting researcher with [Chuan Guo](https://sites.google.com/view/chuanguo) at [Meta FAIR Labs](https://ai.meta.com/research) and [Nicholas Carlini](https://nicholas.carlini.com) at [Google DeepMind](https://deepmind.google), supported by two [BAIR Commons](https://bcommons.berkeley.edu/home) with them. I got my M.Eng. (National Scholarship) and B.Eng. (Summa Cum Laude) from [Shanghai Jiao Tong University](http://en.sjtu.edu.cn) advised by Prof. [Xiaolin Huang](http://www.pami.sjtu.edu.cn/en/xiaolin) and also with Prof. [Cihang Xie](https://cihangxie.github.io).

My research focuses on AI security in real-world applications. I am currently working on prompt injection defenses ([SecAlign](https://arxiv.org/abs/2410.05451), [StruQ](http://arxiv.org/abs/2402.06363), [Jatmo](https://arxiv.org/abs/2312.17673)). [Prompt injections](https://www.ibm.com/topics/prompt-injection) are listed as the [#1 threat](https://genai.owasp.org) to Large Language Model (LLM) Integrated Applications, where a trusted prompt is concatenated to an untrusted data (with potentially injected prompts) as the LLM input. To open up new opportunities for safely using LLMs in systems (e.g., as agents), my goal is to design fundamental defenses to secure LLMs against prompt injections. My work on trustworthy vision models is listed in my [CV](https://drive.google.com/file/d/1UmHL5TfvXIGuNRIPX9DHT_LwRCu1Hkf1/view?usp=sharing) and (previous) [SoP](https://drive.google.com/file/d/1nmocMJFOmw_5_N1roe96Vszhhg7zhaZS/view?usp=sharing). Feel free to drop me an email to connect!

I am fortunate to have mentored lots of talented students (and some from underrepresentative groups): [Jing Qian](https://jing-qian-98.github.io), [Shutong Wu](https://cychomatica.github.io), [Yingwen Wu](https://openreview.net/profile?id=~Yingwen_Wu1), [Zhixing Ye](https://ieeexplore.ieee.org/author/37089933329), [Hend Alzahrani](https://sa.linkedin.com/in/hend-alzahrani), and [Zhengbao He](https://openreview.net/profile?id=~Zhengbao_He1).

Invited Talks
------
+ Security Seminar (UC Berkeley): Prompt Injection Defenses by Structured Queries and Alignment Training (2024)
+ TMLR Young Scientist Seminar (Hong Kong Baptist University): Prompt Injection Defenses by Structured Queries and Alignment Training (2024)
+ ICLR 2023 (oral track): One-Pixel Shortcut: On the Learning Preference of Deep Neural Networks (2023)
+ Youth Ph.D. Talk (AI Time): On the Learning Preference of Deep Neural Networks (2023)
+ CVPR 2022 (oral track): Subspace Adversarial Training (2022)
+ Security Seminar (Northeastern University): Adversarial Attacks and Defenses (2022)

Selected Publications
------
+ Aligning LLMs to Be Robust Against Prompt Injection <br/> **Sizhe Chen**, Arman Zharmagambetov, Saeed Mahloujifar, Kamalika Chaudhuri, Chuan Guo <br/> [[ArXiv Preprint](https://arxiv.org/abs/2410.05451)], [[Code](https://github.com/facebookresearch/SecAlign)]
+ StruQ: Defending Against Prompt Injection with Structured Queries <br/> **Sizhe Chen**, Julien Piet, Chawin Sitawarin, David Wagner <br/> [[USENIX Security'25](http://arxiv.org/abs/2402.06363)], [[Code](https://github.com/Sizhe-Chen/StruQ)]
+ One-Pixel Shortcut: On the Learning Preference of Deep Neural Networks <br/> Shutong Wu\*, **Sizhe Chen\***, Cihang Xie, Xiaolin Huang <br/> [[ICLR'23 (Spotlight)](https://openreview.net/forum?id=p7G8t5FVn2h)], [[Code](https://github.com/cychomatica/One-Pixel-Shotcut)]
+ Adversarial Attack on Attackers: Post-Process to Mitigate Black-Box Score-Based Attacks <br/> **Sizhe Chen**, Zhehao Huang, Qinghua Tao, Yingwen Wu, Cihang Xie, Xiaolin Huang <br/> [[NeurIPS'22](https://openreview.net/forum?id=7hhH95QKKDX)], [[Code](https://github.com/Sizhe-Chen/AAA)]
+ Universal Adversarial Attack on Attention and the Resulting Dataset DAmageNet <br/> **Sizhe Chen**, Zhengbao He, Chengjin Sun, Jie Yang, Xiaolin Huang <br/> [[TPAMI'22](https://ieeexplore.ieee.org/document/9238430)], [[Code](https://github.com/Sizhe-Chen/DAmageNet)]
+ Subspace Adversarial Training <br/> Tao Li, Yingwen Wu, **Sizhe Chen**, Kun Fang, Xiaolin Huang <br/> [[CVPR'22 (Oral)](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Subspace_Adversarial_Training_CVPR_2022_paper)], [[Code](https://github.com/nblt/Sub-AT)]

Services
------
+ Conference Reviewer: SaTML'25, CCS'24, ICML'24, NeurIPS'23, ICLR'23-25, CVPR'23/24, ICCV'23, ECCV'22/24
+ Journal Reviewer: IEEE TPAMI, Machine Learning, Pattern Recognition
+ UC Berkeley Computer Science Faculty Hiring Committee: 2024
+ UC Berkeley [Equal Access to Application Assistance (EEEA)](https://sites.google.com/berkeley.edu/eaaa/home) Program Reviewer: 2024

Misc
------
+ I love to play badminton, lift weights, write [blogs](http://xhslink.com/5JP3XI), and attend concerts.
+ I directed three 1K-spectator concerts. <br/>

![](https://github.com/Sizhe-Chen/Sizhe-Chen.github.io/blob/master/images/piano.jpg?raw=true)
