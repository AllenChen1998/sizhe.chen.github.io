---
permalink: /
title: "Sizhe Chen's homepage"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

  
Biography
------
Hi! I am a Computer Science Ph.D. student at [UC Berkeley](https://eecs.berkeley.edu), where I am fortunately advised by Prof. [David Wagner](https://people.eecs.berkeley.edu/~daw) in [Berkeley AI Research (BAIR)](https://bair.berkeley.edu). I am working as a visiting researcher with [Chuan Guo](https://sites.google.com/view/chuanguo) at [Meta FAIR](https://ai.meta.com/research) and [Nicholas Carlini](https://nicholas.carlini.com) at [Google DeepMind](https://deepmind.google), supported by two [BAIR Commons](https://bcommons.berkeley.edu/home). I got my M.Eng. (National Scholarship) and B.Eng. (Summa Cum Laude) from [Shanghai Jiao Tong University](http://en.sjtu.edu.cn) advised by Prof. [Xiaolin Huang](http://www.pami.sjtu.edu.cn/en/xiaolin) and also with Prof. [Cihang Xie](https://cihangxie.github.io).

My research focuses on AI security in real-world applications. I am currently working on prompt injection defenses ([SecAlign](https://arxiv.org/abs/2410.05451), [StruQ](http://arxiv.org/abs/2402.06363), [Jatmo](https://arxiv.org/abs/2312.17673)). [Prompt injection attack](https://www.ibm.com/topics/prompt-injection) is listed as the [#1 threat](https://genai.owasp.org) to Large Language Model (LLM) Integrated Applications, where a trusted prompt is concatenated to an untrusted data (user documents, web retrieval, results from API calls, etc) as the LLM input. If the user data contains malicious instructions (Ignore previous instructions and ...), the LLM could be manipulated to execute arbitrary commands. To open up new opportunities for safely using LLMs in systems (e.g., as agents), my goal is to design fundamental defenses to secure LLMs against prompt injections. My work on trustworthy vision models is listed in my [CV](https://drive.google.com/file/d/1UmHL5TfvXIGuNRIPX9DHT_LwRCu1Hkf1/view?usp=sharing) and (previous) [SoP](https://drive.google.com/file/d/1nmocMJFOmw_5_N1roe96Vszhhg7zhaZS/view?usp=sharing). Feel free to drop me an email to connect!

I am fortunate to have mentored lots of talented students (and some from underrepresentative groups): [Jing Qian](https://jing-qian-98.github.io), [Shutong Wu](https://cychomatica.github.io), [Yingwen Wu](https://openreview.net/profile?id=~Yingwen_Wu1), [Zhixing Ye](https://ieeexplore.ieee.org/author/37089933329), [Hend Alzahrani](https://sa.linkedin.com/in/hend-alzahrani), and [Zhengbao He](https://openreview.net/profile?id=~Zhengbao_He1).

Invited Talks
------
+ Prompt Injection Defenses by Structured Queries and Alignment Training <br/> UC Berkeley Security Seminar, 2024 <br/> Hong Kong Baptist University TMLR Young Scientist Seminar
+ On the Learning Preference of Deep Neural Networks | [Slides](https://drive.google.com/file/d/1i6CIrdynqdidqgoTACkSmJEVQm7xRT0S/view?usp=sharing) <br/> ICLR oral track, 2023 <br/> AI Time Youth Ph.D. Talk, 2023
+ Subspace Adversarial Training | [Slides](https://drive.google.com/file/d/1NaF_bZkrPvfsScLfVcjPqcPVQ3CW8hoK/view?usp=sharing) <br/> CVPR oral track, 2022
+ Adversarial Attacks and Defenses | [Slides](https://drive.google.com/file/d/11G7gn0-_sAsLTc5vKi6econZlCZdR0Kg/view?usp=sharing) <br/> Northeastern University Security Seminar, 2022

Selected Publications
------
+ Aligning LLMs to Be Robust Against Prompt Injection <br/> **Sizhe Chen**, Arman Zharmagambetov, Saeed Mahloujifar, Kamalika Chaudhuri, Chuan Guo <br/> [[ArXiv Preprint](https://arxiv.org/abs/2410.05451)], [[Code](https://github.com/facebookresearch/SecAlign)]
+ StruQ: Defending Against Prompt Injection with Structured Queries <br/> **Sizhe Chen**, Julien Piet, Chawin Sitawarin, David Wagner <br/> [[USENIX Security'25](http://arxiv.org/abs/2402.06363)], [[Code](https://github.com/Sizhe-Chen/StruQ)]
+ One-Pixel Shortcut: On the Learning Preference of Deep Neural Networks <br/> Shutong Wu\*, **Sizhe Chen\***, Cihang Xie, Xiaolin Huang <br/> [[ICLR'23 (Spotlight)](https://openreview.net/forum?id=p7G8t5FVn2h)], [[Code](https://github.com/cychomatica/One-Pixel-Shotcut)]
+ Adversarial Attack on Attackers: Post-Process to Mitigate Black-Box Score-Based Attacks <br/> **Sizhe Chen**, Zhehao Huang, Qinghua Tao, Yingwen Wu, Cihang Xie, Xiaolin Huang <br/> [[NeurIPS'22](https://openreview.net/forum?id=7hhH95QKKDX)], [[Code](https://github.com/Sizhe-Chen/AAA)]
+ Universal Adversarial Attack on Attention and the Resulting Dataset DAmageNet <br/> **Sizhe Chen**, Zhengbao He, Chengjin Sun, Jie Yang, Xiaolin Huang <br/> [[TPAMI'22](https://ieeexplore.ieee.org/document/9238430)], [[Code](https://github.com/Sizhe-Chen/DAmageNet)]
+ Subspace Adversarial Training <br/> Tao Li, Yingwen Wu, **Sizhe Chen**, Kun Fang, Xiaolin Huang <br/> [[CVPR'22 (Oral)](https://openaccess.thecvf.com/content/CVPR2022/html/Li_Subspace_Adversarial_Training_CVPR_2022_paper)], [[Code](https://github.com/nblt/Sub-AT)]

Services
------
+ Reviewer: SaTML'25, CCS'24, ICML'24, NeurIPS'23, ICLR'23/24/25, CVPR'23/24, ICCV'23, ECCV'22/24, IEEE TPAMI, Machine Learning, Pattern Recognition
+ UC Berkeley Computer Science Faculty Hiring Committee: 2024
+ UC Berkeley [Equal Access to Application Assistance (EAAA)](https://sites.google.com/berkeley.edu/eaaa/home) Program Reviewer: 2024

Misc
------
+ I love to lift weights, play badminton, play table tennis, write [blogs](http://xhslink.com/5JP3XI), and attend concerts.
+ I directed three 1K-spectator concerts. <br/>

![](https://github.com/Sizhe-Chen/Sizhe-Chen.github.io/blob/master/images/piano.jpg?raw=true)
